{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8.607935876849949"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.io\n",
    "from scipy.signal import filtfilt, butter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "fs = 125\n",
    "\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def BandpassFilter(signal, pass_band=(40/60,240/60), fs=125):\n",
    "    \"\"\"\n",
    "    Butterworth bandpass filter algorithm.\n",
    "    \n",
    "    Returns:\n",
    "        Bandpass filtered signal\n",
    "    \"\"\"          \n",
    "    b, a = sp.signal.butter(2, pass_band, btype='bandpass', fs = fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def FourierTransform(signal, fs):\n",
    "    \"\"\"\n",
    "    Run a Fourier Transform on a signal\n",
    "    \n",
    "    Returns:\n",
    "        Freq and Magnitude of the signal\n",
    "    \"\"\"\n",
    "    freqs = np.fft.rfftfreq(2 * len(signal), 1 / fs)\n",
    "    fft = np.abs(np.fft.rfft(signal, 2 * len(signal)))\n",
    "    return freqs, fft\n",
    "\n",
    "def createFeatures(ppg, accmag, fs):\n",
    "    \"\"\"\n",
    "    Creates features for Random Forest Regressor.\n",
    "    \n",
    "    Returns:\n",
    "        Dominant frequency for PPG & Accelerometer Magnitude signals\n",
    "    \"\"\"\n",
    "    \n",
    "    freqs, ppg_fft = FourierTransform(ppg, fs)\n",
    "    freqs, accmag_fft = FourierTransform(accmag, fs)\n",
    "    \n",
    "    ppg_dominant_freq = freqs[np.argmax(ppg_fft)]\n",
    "    accmag_dominant_freq = freqs[np.argmax(accmag_fft)]\n",
    "    \n",
    "    return np.array([ppg_dominant_freq, accmag_dominant_freq])\n",
    "\n",
    "def randomForestRegression(features, labels):\n",
    "    \"\"\"\n",
    "    Trains Random Forest Regression model.\n",
    "    \n",
    "    Returns:\n",
    "        Trained model\n",
    "    \"\"\"\n",
    "    \n",
    "    clf = RandomForestRegressor(n_estimators=250, max_depth=8, random_state=43)\n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    \n",
    "    for train_idx, test_idx in kf.split(features, labels):\n",
    "        train_X, train_y = features[train_idx], labels[train_idx]\n",
    "        clf.fit(train_X, train_y)\n",
    "    \n",
    "    return clf\n",
    "    \n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl):\n",
    "    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    ppg, accx, accy, accz = LoadTroikaDataFile(data_fl)\n",
    "    ref_bpm  = sp.io.loadmat(ref_fl)['BPM0'].squeeze()\n",
    "    fs = 125\n",
    "    \n",
    "    # Caculates magnitude of accelerometer\n",
    "    acc_mag = np.sqrt(np.sum(np.square(np.vstack((accx, accy, accz))), axis = 0))\n",
    "    \n",
    "    # The dataset gives the BPM value in every 8-second time window and two successive time windows overlap by 6 seconds.\n",
    "    window_length_fs = 8 * fs\n",
    "    window_shift_fs = 2 * fs\n",
    "    \n",
    "    features, filt_signals = [], []\n",
    "    errors, confidence = [], []\n",
    "    labels = []\n",
    "    k = 0\n",
    "    \n",
    "    for i in range(0, len(ppg) - window_length_fs, window_shift_fs):\n",
    "        \n",
    "        # Bandpass signal between 40-240BPM.\n",
    "        filt_ppg = BandpassFilter(ppg[i : i + window_shift_fs])\n",
    "        filt_accmag = BandpassFilter(acc_mag[i : i + window_shift_fs])\n",
    "        \n",
    "        filt_signals.append([filt_ppg, filt_accmag])\n",
    "        \n",
    "        # Compute features for random forest model.\n",
    "        features.append(createFeatures(filt_ppg, filt_accmag, fs))\n",
    "        labels.append(ref_bpm[k])\n",
    "        k += 1\n",
    "        \n",
    "    features = np.array(features)\n",
    "    \n",
    "    # Trains RandomForestRegressor model which will estimate pulse rate (in BPM).\n",
    "    model = randomForestRegression(features, np.array(labels))\n",
    "    \n",
    "    for i in range(len(filt_signals)):\n",
    "        filt_ppg, filt_accmag = filt_signals[i]\n",
    "        feature, true_bpm = features[i], labels[i]\n",
    "        \n",
    "        # Predicts the estimated pulse rate using trained random forest model.\n",
    "        est_bpm = model.predict(feature.reshape((1, -1)))[0]\n",
    "        \n",
    "        # Calculates absolute error b/w ground-truth BPM and estimated BPM.\n",
    "        errors.append(np.abs(true_bpm - est_bpm))\n",
    "        \n",
    "        freqs, ppg_fft = FourierTransform(ppg, fs)\n",
    "        \n",
    "        window_f = 45 / 60\n",
    "        est_frequency_window = (freqs > (est_bpm / 60) - window_f) & (freqs < (est_bpm / 60) + window_f)\n",
    "        \n",
    "        # Confidence is estimated by summing the frequency spectrum near the pulse rate estimate and dividing it by the sum of the entire spectrum.\n",
    "        ppg_power = np.sum(ppg_fft[est_frequency_window])\n",
    "        total_power = np.sum(ppg_fft)\n",
    "        confidence.append(ppg_power / total_power)\n",
    "        \n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    return np.array(errors), np.array(confidence)\n",
    "Evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
